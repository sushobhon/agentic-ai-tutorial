{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0611d39",
   "metadata": {},
   "source": [
    "## Notebook Contains\n",
    "\n",
    "A Rag Agent using `Cewai` with short term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfb147",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbc406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "import io\n",
    "import contextlib\n",
    "import ollama\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from crewai import Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280c26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ollama/llama3.2:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d65bef",
   "metadata": {},
   "source": [
    "## Creating Supervisor Agent with memory\n",
    "This class will act as long term memory (persisted between runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7500e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SQLLightMemory:\n",
    "#     def __init__(self, db_path = 'memory.db'):\n",
    "#         self.conn = sqlite3.connect(db_path)\n",
    "#         self.cur = self.conn.cursor(db_path)\n",
    "#         self.cur.execute(\"\"\"\"\n",
    "#                          CREATE TABLE IF NOT EXISTS memory(\n",
    "#                             id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#                             role TEXT,\n",
    "#                             content TEXT,\n",
    "#                             timestamp TEXT\n",
    "#                          )\"\"\"\n",
    "#                         )\n",
    "#         self.conn.commit()\n",
    "    \n",
    "#     # Saving a new record\n",
    "#     def save(self, role, content):\n",
    "#         ts = datetime.datetime.now().isoformat()\n",
    "#         self.cur.execute(\"\"\"\"INSERT INTO memory (role, content, timestamp) VALUES (?, ?, ?)\"\"\", (role, content, ts))\n",
    "#         self.conn.commit()\n",
    "    \n",
    "#     # load most recent recors\n",
    "#     def load_recent(self, limit = 10):\n",
    "#         self.cur.execute(\"\"\"\"\n",
    "#             SELECT role, content\n",
    "#             FROM memory\n",
    "#             ORDER BY id DESC LIMIT ?                 \n",
    "#         \"\"\", (limit))\n",
    "#         return self.cur.fetchall()\n",
    "\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "class SQLiteMemory:\n",
    "    def __init__(self, db_path=\"memory.db\"):\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS memory (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                role TEXT,\n",
    "                content TEXT,\n",
    "                timestamp TEXT\n",
    "            )\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    def save(self, role, content):\n",
    "        ts = datetime.datetime.now().isoformat()\n",
    "        self.cur.execute(\"INSERT INTO memory (role, content, timestamp) VALUES (?, ?, ?)\", \n",
    "                         (role, content, ts))\n",
    "        self.conn.commit()\n",
    "\n",
    "    def load_recent(self, limit=10):\n",
    "        self.cur.execute(\"SELECT role, content FROM memory ORDER BY id DESC LIMIT ?\", (limit,))\n",
    "        return self.cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd235f7",
   "metadata": {},
   "source": [
    "## Creating Python Coad Runner (Coading Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51afb87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Seafly run Python code and return output\"\"\"\n",
    "    print(f\"\\t{code}\")\n",
    "    try:\n",
    "        buffer = io.StringIO()\n",
    "        with contextlib.redirect_stdout(buffer):\n",
    "            exec(code, {})\n",
    "        return buffer.getvalue() or \"Code executed successfully (no output)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error running the code: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6294ab5d",
   "metadata": {},
   "source": [
    "## Creating RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e18d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGChromaBD:\n",
    "    def __init__(self, persist_dir = \"./chroma_db\"):\n",
    "        self.client = chromadb.PersistentClient(path=persist_dir)\n",
    "        self.model =  SentenceTransformer(\"all-MiniLM-L6-V2\")\n",
    "\n",
    "        # Create or Get connection\n",
    "        self.collection = self.client.get_or_create_collection(\n",
    "            name= \"knowledge_base\"\n",
    "        )\n",
    "\n",
    "    # Adding Document\n",
    "    def add_documents(self, docs):\n",
    "        embeddings = self.model.encode(docs).tolist()\n",
    "        ids = [f\"doc_{i}\" for i in range(len(docs))]\n",
    "        self.collection.add(documents=docs, embeddings= embeddings, ids=ids)\n",
    "\n",
    "    # Query document\n",
    "    def query(self, question, k=3):\n",
    "        q_emb = self.model.encode([question]).tolist()\n",
    "        results = self.collection.query(\n",
    "            query_embeddings= q_emb,\n",
    "            n_results= k\n",
    "        )\n",
    "        return results[\"documents\"][0] if results[\"documents\"] else []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b847f108",
   "metadata": {},
   "source": [
    "## Creating Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b166e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SQLiteMemory()\n",
    "ragdb = RAGChromaBD()\n",
    "\n",
    "# preload docs into Chroma\n",
    "ragdb.add_documents([\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"LangChain is a framework for building agents.\",\n",
    "    \"Albert Einstein developed the theory of relativity.\"\n",
    "])\n",
    "\n",
    "supervisor = Agent(\n",
    "    role= \"supervisor\",\n",
    "    goal = \"Route user queries to the right agent. Maintain long-term memory in SQLite.\",\n",
    "    backstory= (\n",
    "        \"You are the main controller. You chat with the human, \"\n",
    "        \"decide if the query needs coding, knowledge retrieval, or casual chat.\"\n",
    "    ),\n",
    "    llm= MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe752b",
   "metadata": {},
   "source": [
    "## Task Orchestration (Supervisor Chooses Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08c96dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisorAgent:\n",
    "    def __init__(self, memory: SQLiteMemory, model = MODEL_NAME):\n",
    "        self.memory = memory\n",
    "        self.model = model\n",
    "        \n",
    "    # method to deside which tools to use\n",
    "    def decide_tool(self, query: str) -> str:\n",
    "        context = self.memory.load_recent(limit=3)\n",
    "        history = \"\\n\".join([f\"{r}: {c}\" for r, c in context])\n",
    "\n",
    "        system_prompt = \"\"\"\n",
    "            You are a Supervisor Agent that decides which specialized agent should handle a user query.\n",
    "            Available agents:\n",
    "            1. \"coding_agent\" → for math/code/executing Python\n",
    "            2. \"rag_agent\" → for factual/knowledge/research questions\n",
    "            3. \"chat\" → for general conversation or casual talk\n",
    "\n",
    "            Rules:\n",
    "            - Respond ONLY with one of: coding_agent, rag_agent, chat\n",
    "            - Do not explain your choice\n",
    "        \"\"\"\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model = self.model,\n",
    "            messages = [\n",
    "                {\"role\":\"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Conversation history:\\n{history}\\n\\nUser query: {query}\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        decision = response[\"message\"][\"content\"].strip().lower()\n",
    "        return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2864d8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision: coding_agent\n",
      "user_query: 12 * (3+2)\n",
      "\t12 * (3+2)\n",
      "Code executed successfully (no output)\n",
      "Decision: chat\n",
      "[Chat]: Sure! You said: Hello, how are you?\n"
     ]
    }
   ],
   "source": [
    "# Assume coding_agent and rag_agent are already defined\n",
    "\n",
    "memory = SQLiteMemory()\n",
    "supervisor = SupervisorAgent(memory=memory, model=\"llama3.2:latest\")\n",
    "\n",
    "def agentic_loop(user_query):\n",
    "    decision = supervisor.decide_tool(user_query)\n",
    "\n",
    "    print(f\"Decision: {decision}\")\n",
    "    if decision == \"coding_agent\":\n",
    "        print(f\"user_query: {user_query}\")\n",
    "        result = run_python_code(user_query)\n",
    "        memory.save(\"coding_agent\", result)\n",
    "    elif decision == \"rag_agent\":\n",
    "        docs = ragdb.query(user_query)\n",
    "        result = \"\\n\".join(docs)\n",
    "        memory.save(\"rag_agent\", result)\n",
    "    else:\n",
    "        result = f\"[Chat]: Sure! You said: {user_query}\"\n",
    "        memory.save(\"chat\", result)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# 🔥 Test\n",
    "# print(agentic_loop(\"What is the theory of relativity?\"))  # → rag_agent\n",
    "print(agentic_loop(\"12 * (3+2)\"))                        # → coding_agent\n",
    "print(agentic_loop(\"Hello, how are you?\"))               # → chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf3e4722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🙎‍♂️: print Hello world\n",
      "🤖: As your supervisor, I noted your query: 'print Hello world'. Let's discuss!\n",
      "\n",
      "🙎‍♂️: exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    print(f\"\\n🙎‍♂️: {user_input}\")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    output = supervisor_router(user_input)\n",
    "    print(f\"🤖: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99815e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

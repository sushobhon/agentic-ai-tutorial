{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0611d39",
   "metadata": {},
   "source": [
    "## Notebook Contains\n",
    "\n",
    "A Rag Agent using `Cewai`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfb147",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beace73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000186F5A0BF20>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30.0)'))\n",
      "HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000186FA0EA060>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30.0)'))\n"
     ]
    }
   ],
   "source": [
    "# Importing Necessaet Libraries\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "from crewai import LLM, Agent, Task, Crew\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from crewai.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8438f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration --- #\n",
    "MODEL_NAME = \"ollama/openhermes:latest\"\n",
    "# DATA_FILE = \"Data\"\n",
    "# DATA_FILE = os.path.join(DATA_FILE, \"HR_Policy.txt\")\n",
    "# VECTORSTORE_DIR = \"hr_policy_vectorstore\"\n",
    "# EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "# CHUNK_SIZE = 1000\n",
    "# CHUNK_OVERLAP = 150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac164200",
   "metadata": {},
   "source": [
    "## Creating Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb36bf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading and Chunking the Data\n",
    "# def load_and_chunk_documents():\n",
    "#     \"\"\"\"Loads the HR policy data from the TXT file and splits it into smaller chunks.\"\"\"\n",
    "#     print(\"\\t --- Step 1: Loading and Chunking Data ---\")\n",
    "\n",
    "#     if not os.path.exists(DATA_FILE):\n",
    "#         print(f\"Data file {DATA_FILE} does not exist.\")\n",
    "#         return None\n",
    "\n",
    "#     # Read the text file\n",
    "#     with open(DATA_FILE, 'r', encoding='utf-8') as file:\n",
    "#         full_text = file.read()\n",
    "    \n",
    "#     # Split the text into chunks\n",
    "#     documents = [full_text]\n",
    "\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         chunk_size= CHUNK_SIZE,\n",
    "#         chunk_overlap= CHUNK_OVERLAP\n",
    "#     )\n",
    "\n",
    "#     chunks = text_splitter.create_documents(documents)\n",
    "#     print(f\"Data loaded and split into {len(chunks)} chunks.\")\n",
    "#     return chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdb82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating and embedding the Vector Store\n",
    "# def create_and_store_embeddings(chunks):\n",
    "#     \"\"\"Creates a vector store from the chunks of data.\"\"\"\n",
    "#     print(\"\\t --- Step 2: Creating Vector Store ---\")\n",
    "\n",
    "#     if not chunks:\n",
    "#         print(\"No chunks to create vector store.\")\n",
    "#         return None\n",
    "\n",
    "#     # Initialize the embedding model from HuggingFace\n",
    "#     print(f\"Loading embedding model: '{EMBEDDING_MODEL}'...\")\n",
    "#     embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "#     # Create the Chroma vector store\n",
    "#     # This will process all chunks and store their vector representations.\n",
    "#     # It will be persisted to disk in the VECTORSTORE_DIR.\n",
    "#     print(f\"Creating vector store in '{VECTORSTORE_DIR}'...\")\n",
    "#     Chroma.from_documents(\n",
    "#         chunks,\n",
    "#         embeddings,\n",
    "#         persist_directory=VECTORSTORE_DIR\n",
    "#     )\n",
    "#     print(\"Vector store created and persisted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba4cd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Manually download the dataset first as per the instructions in the function.\n",
    "# doc_chunks = load_and_chunk_documents()\n",
    "# if doc_chunks:\n",
    "#     create_and_store_embeddings(doc_chunks)\n",
    "# print(\"\\n\\t--- Data Ingestion Complete ---\")\n",
    "# print(f\"Vector store is ready in the '{VECTORSTORE_DIR}' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c36eef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- 1. RAG Agent with Crew.ai --- #\n",
    "# # Initialize embeddings and vector store once to be used by the tool\n",
    "# print(\"Loading embeddings and vector store for RAG tool...\")\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "# vectorstore = Chroma(\n",
    "#     persist_directory=VECTORSTORE_DIR,\n",
    "#     embedding_function=embeddings\n",
    "# )\n",
    "# retiver = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d953e2c",
   "metadata": {},
   "source": [
    "## Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0deff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining retrieval tool\n",
    "# class RetrieveHRPolicy(BaseTool):\n",
    "#     name: str = \"RetrieveHRPolicy\"\n",
    "#     description: str = \"Retrives relevant HR policy information based on the query.\"\n",
    "\n",
    "#     def _run(self, query: str) -> str:\n",
    "#         \"\"\"Run the retrieval tool to get relevant HR policy information.\"\"\"\n",
    "#         # print(f\"Retrieving information for query: {query}\")\n",
    "#         results = retiver.invoke(query)\n",
    "\n",
    "#         if not results:\n",
    "#             return \"No relevant information found in the vector database.\"\n",
    "        \n",
    "#         context = \"\\n\".join([doc.page_content for doc in results])\n",
    "#         # print(\"\\t--- RAG Tool Finished ---\")\n",
    "#         return f\"Retrieved context: \\n{context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a392df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodingAgent(BaseTool):\n",
    "    name: str = \"CodingAgent\"\n",
    "    description: str = \"\"\"A coding agent that can write and execute Python code based on user queries.\n",
    "    It returns the output of the code if successful, or an error message if an error occurs.\n",
    "    The query must be a valid Python code block.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Run the coding agent to write and execute Python code based on the query.\"\"\"\n",
    "        \n",
    "        # We need to capture the output, so we redirect stdout to a string buffer.\n",
    "        old_stdout = sys.stdout\n",
    "        redirected_output = io.StringIO()\n",
    "        sys.stdout = redirected_output\n",
    "        \n",
    "        try:\n",
    "            # Execute the user's query as a code block.\n",
    "            # The 'exec' function can run multi-line statements, including imports and function definitions.\n",
    "            exec(query)\n",
    "            \n",
    "            # Get the output from the redirected buffer.\n",
    "            output = redirected_output.getvalue()\n",
    "            \n",
    "            # Restore the original stdout.\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "            # If there's no output, we return a message indicating success.\n",
    "            if not output.strip():\n",
    "                return \"Code executed successfully with no output.\"\n",
    "            \n",
    "            # Return the captured output.\n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during execution, capture it and return the error message.\n",
    "            # Restore the original stdout first.\n",
    "            sys.stdout = old_stdout\n",
    "            return f\"An error occurred while executing the code: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b7f25b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coading_tool = CodingAgent()\n",
    "\n",
    "print(coading_tool._run(\"print('Hello')\"))  # Test the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537e3d8",
   "metadata": {},
   "source": [
    "## Initializing LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee3a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuring the LLM --- #\n",
    "llm = LLM(\n",
    "    model= MODEL_NAME,\n",
    "    temperature=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tools\n",
    "retrival_tool = CodingAgent()\n",
    "\n",
    "# define Agent first\n",
    "agent = Agent(\n",
    "    role=\"Coading Agent\",\n",
    "    goal=\"\"\"Write python code based on user queries and answer executing code.\"\"\",\n",
    "    backstory= \"\"\"You are a helpful assistant. You can write and execute Python code based on user queries and return the output,\n",
    "      executing the code.\"\"\",\n",
    "    # verbose=True,\n",
    "    verbose=False,\n",
    "    tools=[retrival_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Define Task\n",
    "task = Task(\n",
    "    description=f\"\"\"Write clean python code based on the user query.\n",
    "    User Query: {{query}}\"\"\",\n",
    "    expected_output=\"return the code like ```CODE:\\n``` and the output of the code.\",\n",
    "    agent=agent\n",
    ")\n",
    "\n",
    "# Define Crew\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    # verbose=True\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de2eb7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Python code to print the sum of the first 10 odd numbers:\n",
      "```python\n",
      "sum = 0\n",
      "for i in range(1, 21, 2):\n",
      "    sum += i\n",
      "print(sum)\n",
      "```\n",
      "The output of this code is 100.\n"
     ]
    }
   ],
   "source": [
    "# Checking if Crew is ready\n",
    "print(crew.kickoff(inputs={\"query\": \"write a python code yo print the sum of first 10 odd numbers.\"}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c375b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defning Main Function\n",
    "def main():\n",
    "    \"\"\"Main function to kickoff the Crew.\"\"\"\n",
    "    print(\"\\n\\t--- Starting Crew for RAG Agent ---\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "        print(f\"\\n🙎‍♂️: {user_query}\")\n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Exiting the Crew. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Kickoff the Crew with the user query\n",
    "        response = crew.kickoff(inputs={\"query\": user_query})\n",
    "        print(f\"🤖: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ea290f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t--- Starting Crew for RAG Agent ---\n",
      "\n",
      "🙎‍♂️: How do I request time off and what is the process for approval?\n",
      "🤖: To request time off, you should follow the designated process outlined in the employee handbook. Typically, this involves submitting a request through an online system or directly to your immediate supervisor or the HR department. The request should include the desired dates and the reason for the time off. Approval is subject to manager discretion and business needs, and you will receive a response confirming or denying your request.\n",
      "\n",
      "🙎‍♂️: How can I update my personal information, such as address or emergency contacts?\n",
      "🤖: To update your personal information, such as address or emergency contacts, you should notify the HR department or use the designated employee self-service portal, if available. HR will provide the necessary forms or instructions to make the updates. It is essential to keep personal information current to ensure effective communication and for emergency situations.\n",
      "\n",
      "🙎‍♂️: What is Termination Due to Restructuring or Economic Reasons?\n",
      "🤖: Termination due to restructuring or economic reasons refers to layoffs or retrenchments that may occur in a business due to restructuring, downsizing, or economic constraints. Employees affected by this will be treated fairly and sensitively, following applicable labor laws and providing appropriate support and benefits as per company policy.\n",
      "\n",
      "🙎‍♂️: exit\n",
      "Exiting the Crew. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

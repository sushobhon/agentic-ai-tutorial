{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04720e2c",
   "metadata": {},
   "source": [
    "# Notebook Details\n",
    "\n",
    "In this notebook we will give Long term memory.\n",
    "\n",
    "We have 2 tools:\n",
    "- 1. Calculator Tools.\n",
    "- 2. wikipwdia web search.\n",
    "\n",
    "We will store old conversion to a list and pass this histoy as context of the query.\n",
    "\n",
    "As of now the agent can answer only one query. But We will add looping concept here, So that we can interact with the agent as long as we want.\n",
    "\n",
    "In Previous Notebook we have build it feom scratch. This time we will be using popular freamwork called `langchain` to build the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130febd",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a240da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install necessary libraries\n",
    "# importing necessary libraries\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import wikipedia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105a9d3",
   "metadata": {},
   "source": [
    "## Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9bdad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration --- #\n",
    "MODEL_NAME = \"llama3.2:latest\"\n",
    "# MEMORY_PATH = \"memory_V2.json\"\n",
    "# MAX_MEMORY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16bed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Simple calculator tool\n",
    "def calculator_tool(query):\n",
    "    \"\"\"A simple calculator tool.\"\"\"\n",
    "    try:\n",
    "        # Keep only numbers, operators, parentheses, and dots\n",
    "        cleaned_expr = query.split('=')[0]  # Remove anything after '='\n",
    "        cleaned_expr = \"\".join(cleaned_expr).strip()\n",
    "        return str(eval(cleaned_expr))\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f14bafc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Wikipedia search tool\n",
    "# def clean_text(text):\n",
    "#     \"\"\"Remove HTML tags and excessive whitespace.\"\"\"\n",
    "#     # If HTML is present, parse it\n",
    "#     soup = BeautifulSoup(text, \"html.parser\")\n",
    "#     clean = soup.get_text(separator=\" \", strip=True)\n",
    "#     # Remove multiple spaces/newlines\n",
    "#     clean = re.sub(r\"\\s+\", \" \", clean)\n",
    "#     return clean\n",
    "\n",
    "\n",
    "# def web_search(query):\n",
    "#     url = \"https://en.wikipedia.org/w/api.php\"\n",
    "#     params = {\n",
    "#         \"action\": \"query\",\n",
    "#         \"list\": \"search\",\n",
    "#         \"srsearch\": query,\n",
    "#         \"format\": \"json\"\n",
    "#     }\n",
    "#     try:\n",
    "#         response = requests.get(url, params=params)\n",
    "#         data = response.json()\n",
    "#         if \"query\" in data and \"search\" in data[\"query\"]:\n",
    "#             results = []\n",
    "#             for item in data['query']['search']:\n",
    "#                 # Remove HTML Tags\n",
    "#                 clean_text = re.sub(r'<[^>]+>', '', item['snippet'])\n",
    "#                 results.append(clean_text.strip())\n",
    "#             return \"\\n\".join(results) if results else \"No results found on Wikipedia.\"\n",
    "#         else:\n",
    "#             return \"No results found.\"\n",
    "#     except Exception as e:\n",
    "#         return f\"Error searching Wikipedia: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9de844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Wikipedia search tool\n",
    "def wikipedia_tool(query):\n",
    "    \"\"\"Search Wikipedia for a given query.\"\"\"\n",
    "    try:\n",
    "        results = wikipedia.search(query, results=5)\n",
    "        if not results:\n",
    "            return \"No results found on Wikipedia.\"\n",
    "        \n",
    "        summaries = []\n",
    "        for title in results:\n",
    "            summary = wikipedia.summary(title, sentences=1)\n",
    "            summaries.append(f\"{title}: {summary}\")\n",
    "        \n",
    "        return \"\\n\".join(summaries)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching Wikipedia: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424a9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wraping the tools in langchain tool objects\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=calculator_tool,\n",
    "        description=\"A simple calculator tool that can perform basic arithmetic operations. Input should be a mathematical expression like '2 + 2'.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Wikipedia Search\",\n",
    "        func=wikipedia_tool,\n",
    "        description=\"Search Wikipedia for a given query. Input should be a search term.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d93d01",
   "metadata": {},
   "source": [
    "## Defining the LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c6cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karmakar\\AppData\\Local\\Temp\\ipykernel_20576\\4231901401.py:1: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL_NAME)\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aacfdd",
   "metadata": {},
   "source": [
    "## Defining Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eee13693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karmakar\\AppData\\Local\\Temp\\ipykernel_20576\\1192691676.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0b2ad",
   "metadata": {},
   "source": [
    "## Defining Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7cf772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining system prompt for the agent\n",
    "system_prompt = f\"\"\"\n",
    "    You are a helpful agent with tools:\n",
    "    1. CALCULATE: for math problems\n",
    "    2. SEARCH: for Wikipedia searches\n",
    "\n",
    "    Decide which tool to use based on the user input.\n",
    "    Respond only with one of the following formats:\n",
    "    CALCULATE: <expression>\n",
    "    SEARCH: <query>\n",
    "    ANSWER: <your direct answer>\n",
    "\n",
    "    User: <query>\n",
    "    Agent:\"\"\"\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"conversational-react-description\", # conversational agent with reasoning\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    agent_kwargs={\"system_prompt\": system_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba89bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Agent started. Type 'exit' to quit.\n",
      "You: What is the sum of first 5 odd numbers\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Calculator\n",
      "Action Input: 1 + 3 + 5 + 7 + 9\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m25\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: The sum of the first 5 odd numbers is 25.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "# ------- Response ------- #\n",
      "Agent: The sum of the first 5 odd numbers is 25.\n",
      "# ------------------------ #\n",
      "You: How old is the current prime minister of India?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: The current Prime Minister of India is Narendra Modi. He has been serving as the Prime Minister since May 2014 and is the leader of the Bharatiya Janata Party (BJP).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "# ------- Response ------- #\n",
      "Agent: The current Prime Minister of India is Narendra Modi. He has been serving as the Prime Minister since May 2014 and is the leader of the Bharatiya Janata Party (BJP).\n",
      "# ------------------------ #\n",
      "You: Who won the recent cricket champieans trophy?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Wikipedia Search\n",
      "Action Input: cricket champions trophy\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mError searching Wikipedia: Page id \"2021 icc champions trophy\" does not match any pages. Try another id!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "\n",
      "AI: The 2020-21 ICC Men's T20 World Cup was the eighth edition of the International Cricket Council's (ICC) Men's T20 World Cup, a Twenty20 international cricket tournament contested by men's teams from around the world. India won the tournament, defeating New Zealand in the final on November 14, 2021.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "# ------- Response ------- #\n",
      "Agent: The 2020-21 ICC Men's T20 World Cup was the eighth edition of the International Cricket Council's (ICC) Men's T20 World Cup, a Twenty20 international cricket tournament contested by men's teams from around the world. India won the tournament, defeating New Zealand in the final on November 14, 2021.\n",
      "# ------------------------ #\n",
      "You: Tell me a joke on Book\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "\n",
      "AI: Why was the book sad? Because it had a bad chapter in its life.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "# ------- Response ------- #\n",
      "Agent: Why was the book sad? Because it had a bad chapter in its life.\n",
      "# ------------------------ #\n",
      "You: exit\n",
      "Exiting the agent. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Creating the conversational loop\n",
    "print(\"ðŸ¤– Agent started. Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    print(f\"You: {user_input}\")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
    "        print(\"Exiting the agent. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    response = agent.run(user_input)\n",
    "    print('# ------- Response ------- #')\n",
    "    print(f\"Agent: {response}\")\n",
    "    print('# ------------------------ #')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e28328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96155caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0611d39",
   "metadata": {},
   "source": [
    "## Notebook Contains\n",
    "\n",
    "A Rag Agent using `Cewai` with short term memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfb147",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7906ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessaet Libraries\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "from crewai import LLM, Agent, Task, Crew, Process\n",
    "from crewai.tools import BaseTool\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280c26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration --- #\n",
    "MODEL_NAME = \"ollama/openhermes:latest\"\n",
    "DATA_FILE = \"Data\"\n",
    "DATA_FILE = os.path.join(DATA_FILE, \"HR_Policy.txt\")\n",
    "VECTORSTORE_DIR = \"hr_policy_vectorstore\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0532d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuring the LLM --- #\n",
    "llm = LLM(\n",
    "    model= MODEL_NAME,\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f52e58",
   "metadata": {},
   "source": [
    "## Vector Database Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf017436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Chunking the Data\n",
    "def load_and_chunk_documents():\n",
    "    \"\"\"\"Loads the HR policy data from the TXT file and splits it into smaller chunks.\"\"\"\n",
    "    print(\"\\t --- Step 1: Loading and Chunking Data ---\")\n",
    "\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"Data file {DATA_FILE} does not exist.\")\n",
    "        return None\n",
    "\n",
    "    # Read the text file\n",
    "    with open(DATA_FILE, 'r', encoding='utf-8') as file:\n",
    "        full_text = file.read()\n",
    "    \n",
    "    # Split the text into chunks\n",
    "    documents = [full_text]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size= CHUNK_SIZE,\n",
    "        chunk_overlap= CHUNK_OVERLAP\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.create_documents(documents)\n",
    "    print(f\"Data loaded and split into {len(chunks)} chunks.\")\n",
    "    return chunks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eadb97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and embedding the Vector Store\n",
    "def create_and_store_embeddings(chunks):\n",
    "    \"\"\"Creates a vector store from the chunks of data.\"\"\"\n",
    "    print(\"\\t --- Step 2: Creating Vector Store ---\")\n",
    "\n",
    "    if not chunks:\n",
    "        print(\"No chunks to create vector store.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize the embedding model from HuggingFace\n",
    "    print(f\"Loading embedding model: '{EMBEDDING_MODEL}'...\")\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "    # Create the Chroma vector store\n",
    "    # This will process all chunks and store their vector representations.\n",
    "    # It will be persisted to disk in the VECTORSTORE_DIR.\n",
    "    print(f\"Creating vector store in '{VECTORSTORE_DIR}'...\")\n",
    "    Chroma.from_documents(\n",
    "        chunks,\n",
    "        embeddings,\n",
    "        persist_directory=VECTORSTORE_DIR\n",
    "    )\n",
    "    print(\"Vector store created and persisted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9851de3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t --- Step 1: Loading and Chunking Data ---\n",
      "Data loaded and split into 25 chunks.\n",
      "\t --- Step 2: Creating Vector Store ---\n",
      "Loading embedding model: 'all-MiniLM-L6-v2'...\n",
      "Creating vector store in 'hr_policy_vectorstore'...\n",
      "Vector store created and persisted successfully.\n",
      "\n",
      "\t--- Data Ingestion Complete ---\n",
      "Vector store is ready in the 'hr_policy_vectorstore' directory.\n"
     ]
    }
   ],
   "source": [
    "# Manually download the dataset first as per the instructions in the function.\n",
    "doc_chunks = load_and_chunk_documents()\n",
    "if doc_chunks:\n",
    "    create_and_store_embeddings(doc_chunks)\n",
    "print(\"\\n\\t--- Data Ingestion Complete ---\")\n",
    "print(f\"Vector store is ready in the '{VECTORSTORE_DIR}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daf675",
   "metadata": {},
   "source": [
    "## Creating RAG Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204fa83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings and vector store for RAG tool...\n"
     ]
    }
   ],
   "source": [
    "# --- 1. RAG Agent with Crew.ai --- #\n",
    "# Initialize embeddings and vector store once to be used by the tool\n",
    "print(\"Loading embeddings and vector store for RAG tool...\")\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=VECTORSTORE_DIR,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "retiver = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6644cf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining retrieval tool\n",
    "class RetrieveHRPolicy(BaseTool):\n",
    "    name: str = \"RetrieveHRPolicy\"\n",
    "    description: str = \"Retrives relevant HR policy information based on the query.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Run the retrieval tool to get relevant HR policy information.\"\"\"\n",
    "        # print(f\"Retrieving information for query: {query}\")\n",
    "        results = retiver.invoke(query)\n",
    "\n",
    "        if not results:\n",
    "            return \"No relevant information found in the vector database.\"\n",
    "        \n",
    "        context = \"\\n\".join([doc.page_content for doc in results])\n",
    "        # print(\"\\t--- RAG Tool Finished ---\")\n",
    "        return f\"Retrieved context: \\n{context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9537f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrival_tool = RetrieveHRPolicy()\n",
    "\n",
    "# retrival_tool._run(\"What is the process for approval to request time off?\")  # Test the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d65bef",
   "metadata": {},
   "source": [
    "## Creating Supervisor Agent with memory\n",
    "This class will act as long term memory (persisted between runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7500e1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "class SQLiteMemory:\n",
    "    def __init__(self, db_path=\"memory.db\"):\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self.cur = self.conn.cursor()\n",
    "        self.cur.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS memory (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                role TEXT,\n",
    "                content TEXT,\n",
    "                timestamp TEXT,\n",
    "                is_checkpoint BOOLEAN DEFAULT 0\n",
    "            )\n",
    "        \"\"\")\n",
    "        self.conn.commit()\n",
    "\n",
    "    def save(self, role, content):\n",
    "        \"\"\"\n",
    "        Saves a single conversation entry to the database.\n",
    "        \n",
    "        Args:\n",
    "            role (str): The role of the speaker (e.g., 'user', 'supervisor_agent').\n",
    "            content (str): The text content of the message.\n",
    "        \"\"\"\n",
    "        ts = datetime.datetime.now().isoformat()\n",
    "        content_json = json.dumps(content)\n",
    "        self.cur.execute(\"INSERT INTO memory (role, content, timestamp) VALUES (?, ?, ?)\", \n",
    "                         (role, content_json, ts))\n",
    "        self.conn.commit()\n",
    "\n",
    "    def load_recent(self, limit=10):\n",
    "        \"\"\"\n",
    "        Loads the most recent conversation entries from the database.\n",
    "        \n",
    "        Args:\n",
    "            limit (int): The number of recent entries to retrieve.\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of tuples containing (role, content) of recent entries.\n",
    "        \"\"\"\n",
    "        self.cur.execute(\"SELECT role, content FROM memory ORDER BY id DESC LIMIT ?\", (limit,))\n",
    "        return self.cur.fetchall()\n",
    "\n",
    "    def save_checkpoint(self, role, content):\n",
    "        \"\"\"\n",
    "        Saves a new entry and marks it as a checkpoint.\n",
    "        This is useful for saving the state after a key decision or action.\n",
    "        \n",
    "        Args:\n",
    "            role (str): The role of the agent making the checkpoint.\n",
    "            content (str): The state or decision to be saved at the checkpoint.\n",
    "            \n",
    "        Returns:\n",
    "            int: The ID of the newly created checkpoint entry.\n",
    "        \"\"\"\n",
    "        ts = datetime.datetime.now().isoformat()\n",
    "        self.cur.execute(\"INSERT INTO memory (role, content, timestamp, is_checkpoint) VALUES (?, ?, ?, ?)\", \n",
    "                         (role, content, ts, 1))\n",
    "        self.conn.commit()\n",
    "        return self.cur.lastrowid\n",
    "\n",
    "    def load_recent(self, limit=10):\n",
    "        \"\"\"\n",
    "        Loads the most recent conversation entries from the database.\n",
    "        \n",
    "        Args:\n",
    "            limit (int): The number of recent entries to retrieve.\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of tuples containing (role, content) of recent entries.\n",
    "        \"\"\"\n",
    "        self.cur.execute(\"SELECT role, content FROM memory ORDER BY id DESC LIMIT ?\", (limit,))\n",
    "        return self.cur.fetchall()\n",
    "    \n",
    "    def load_from_checkpoint(self, checkpoint_id):\n",
    "        \"\"\"\n",
    "        Loads all conversation entries up to and including a specific checkpoint.\n",
    "        \n",
    "        Args:\n",
    "            checkpoint_id (int): The ID of the checkpoint to load from.\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of tuples containing (role, content) for all entries\n",
    "                  up to the specified checkpoint. Returns an empty list if not found.\n",
    "        \"\"\"\n",
    "        self.cur.execute(\"SELECT id FROM memory WHERE id = ? AND is_checkpoint = 1\", (checkpoint_id,))\n",
    "        if not self.cur.fetchone():\n",
    "            print(f\"Error: Checkpoint with ID {checkpoint_id} not found.\")\n",
    "            return []\n",
    "\n",
    "        self.cur.execute(\"SELECT role, content FROM memory WHERE id <= ? ORDER BY id ASC\", (checkpoint_id,))\n",
    "        return self.cur.fetchall()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Closes the database connection.\n",
    "        \"\"\"\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd235f7",
   "metadata": {},
   "source": [
    "## Creating Python Coad Runner (Coading Agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b1ef244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodingAgent(BaseTool):\n",
    "    name: str = \"CodingAgent\"\n",
    "    description: str = \"\"\"A coding agent that can write and execute Python code based on user queries.\n",
    "    It returns the output of the code if successful, or an error message if an error occurs.\n",
    "    The query must be a valid Python code block.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Run the coding agent to write and execute Python code based on the query.\"\"\"\n",
    "        \n",
    "        # We need to capture the output, so we redirect stdout to a string buffer.\n",
    "        old_stdout = sys.stdout\n",
    "        redirected_output = io.StringIO()\n",
    "        sys.stdout = redirected_output\n",
    "        \n",
    "        try:\n",
    "            # Execute the user's query as a code block.\n",
    "            # The 'exec' function can run multi-line statements, including imports and function definitions.\n",
    "            exec(query)\n",
    "            \n",
    "            # Get the output from the redirected buffer.\n",
    "            output = redirected_output.getvalue()\n",
    "            \n",
    "            # Restore the original stdout.\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "            # If there's no output, we return a message indicating success.\n",
    "            if not output.strip():\n",
    "                return \"Code executed successfully with no output.\"\n",
    "            \n",
    "            # Return the captured output.\n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during execution, capture it and return the error message.\n",
    "            # Restore the original stdout first.\n",
    "            sys.stdout = old_stdout\n",
    "            return f\"An error occurred while executing the code: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c04ed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coding_tool = CodingAgent()\n",
    "\n",
    "print(coding_tool._run(\"print('Hello')\"))\n",
    "# print(run_python_code(\"print('Hello World!!!')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910e28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectAnswerTool(BaseTool):\n",
    "    name: str = \"DirectAnswerTool\"\n",
    "    description: str = \"A tool for the supervisor to give a direct, final answer to a query.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        # This tool's purpose is to signal to the crew that a direct answer has been given.\n",
    "        return f\"Supervisor directly answered the query: {query}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550fd6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tools\n",
    "coding_tool = CodingAgent()\n",
    "helper_tool = DirectAnswerTool()\n",
    "retrival_tool = RetrieveHRPolicy()\n",
    "\n",
    "# --- Defining All Agents --- #\n",
    "# Define Coding Agent\n",
    "coding_agent = Agent(\n",
    "    role=\"coding_agent\",\n",
    "    goal=\"\"\"Write python code based on user queries and answer executing code.\"\"\",\n",
    "    backstory= \"\"\"You are a helpful assistant. You can write and execute Python code based on user queries and return the output,\n",
    "      executing the code.\"\"\",\n",
    "    verbose=False,\n",
    "    tools=[coding_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# define Agent first\n",
    "rag_agent = Agent(\n",
    "    role=\"RAG Agent\",\n",
    "    goal=\"\"\"Answering user queries from a vector database. You must use the retrieval tool for every query. \n",
    "        If the tool's response is 'No relevant documents found.', you must respond with \"I don't know the answer.\"\n",
    "        Otherwise, use the retrieved documents to formulate your answer. Do not use any other tools or methods.\"\"\",\n",
    "    backstory= \"\"\"You are a helpful assistant. You can answer user queries from a vector database created from HR policies.\"\"\",\n",
    "    verbose=False,\n",
    "    tools=[retrival_tool],\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Defining Supervisor Agent\n",
    "supervisor_agent = Agent(\n",
    "    role=\"Supervisor Agent\",\n",
    "    goal=\"\"\"Analyze user queries and decide whether to route the request to the Coding Agent or the Helper Agent. Be very strict in your decision-making.\"\"\",\n",
    "    backstory=\"\"\"You are a top-tier assistant that acts as a router for a team of specialized agents.\n",
    "        Your primary function is to classify user requests. You MUST ALWAYS route the query to one of the following agents, by name:\n",
    "        - Coding Agent: For tasks that explicitly require writing, running, or debugging code (e.g., \"write a Python script\", \"calculate X using code\", \"debug this function\").\n",
    "        - RAG Agent: For HR policies question (e.g., \"What are employee benifits?\", \"What are the leave policies?\").\n",
    "        You CAN only select one of these agents.\"\"\",\n",
    "    verbose=False,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# --- Defining Tasks --- #\n",
    "# Defining Coading Task\n",
    "coding_task = Task(\n",
    "    description=f\"\"\"Based on historical context see if the query is related with privious question or not.\n",
    "    Based on your understanding write clean python code based on the user query and historical context.\n",
    "        Historical Context: {{context}}\n",
    "        User Query: {{query}}\"\"\",\n",
    "    expected_output=\"return the code like ```CODE:\\n``` and the output of the code like ```OUTPUT:```.\",\n",
    "    agent=coding_agent\n",
    ")\n",
    "\n",
    "\n",
    "# Defining RAG Task\n",
    "rag_task = Task(\n",
    "    description=f\"\"\"Following is a user Question. First check if the question is related to previously asked question or not.\n",
    "     Based on your understanding use the retrieval tool to find the relevant answer based on HR policies and the historical context.\n",
    "        Historical Context: {{context}}\n",
    "        User Query: {{query}}\"\"\",\n",
    "    expected_output=\"Return short and to the point answer.\",\n",
    "    agent=rag_agent\n",
    ")\n",
    "\n",
    "\n",
    "supervisor_task = Task(\n",
    "    description=f\"\"\"Analyze the user's query and decide on the best course of action.\n",
    "        - If the query is related to math, computer science or coding or if answering the query requirs generating code, delegate to coding_task.\n",
    "        - If the query is Human Resources related question, delegate to rag_task.\n",
    "        - If the query about the conversation history then answer from context and do not suggest any tool.\n",
    "        Context: {{context}}\n",
    "        User Query: {{query}}\"\"\",\n",
    "    expected_output=\"Answer could be 'coding_task' or 'rag_task'. Else The answer will be in Natural language.\",\n",
    "    agent=supervisor_agent,\n",
    "    possible_tasks=[coding_task, rag_task]  # 👈 This is the missing link\n",
    ")\n",
    "\n",
    "# --- Defining Crew --- #\n",
    "# Define Crew\n",
    "coding_crew = Crew(\n",
    "    agents=[coding_agent],\n",
    "    tasks=[coding_task],\n",
    "    verbose=False,\n",
    "    process=Process.sequential, # The supervisor task will run first, and its output will feed into the next task.\n",
    ")\n",
    "\n",
    "\n",
    "rag_crew = Crew(\n",
    "    agents=[rag_agent],\n",
    "    tasks=[rag_task],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "supervisor_crew = Crew(\n",
    "    agents= [supervisor_agent],\n",
    "    tasks= [supervisor_task],\n",
    "    verbose= False,\n",
    "    process= Process.sequential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aa4ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if Crew is ready\n",
    "# print(coading_crew.kickoff(inputs={\"query\": \"calculate the sum of all natural numbers greater than 5 and less than 10.\"}) )\n",
    "# print(helper_crew.kickoff(inputs={'query': \"What is the capital of India?\"}))\n",
    "# print(helper_crew.kickoff(inputs={'query': \"What employee benefits are available?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d83fa84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tuple_list_to_text(data):\n",
    "    \"\"\"\n",
    "    Converts a list of tuples into a formatted text string.\n",
    "\n",
    "    The function iterates through the list, and for each tuple:\n",
    "    - It joins the elements with a colon \":\".\n",
    "    - It handles any complex data types (like nested strings with newlines)\n",
    "      by ensuring they are properly formatted.\n",
    "    - It joins the formatted tuple strings with a newline character \"\\n\".\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of tuples, where each tuple contains strings.\n",
    "\n",
    "    Returns:\n",
    "        str: A single formatted string.\n",
    "    \"\"\"\n",
    "    formatted_parts = []\n",
    "    for item in data:\n",
    "        # Use a list comprehension to handle each element in the tuple\n",
    "        # and ensure a valid string is created.\n",
    "        # The json.loads() is used to correctly handle escaped characters from\n",
    "        # the original string representation, like the newlines in your code.\n",
    "        # We also strip any leading/trailing quotes from the strings.\n",
    "        formatted_elements = []\n",
    "        for element in item:\n",
    "            try:\n",
    "                # Attempt to deserialize from JSON to handle escaped characters\n",
    "                # This is a robust way to handle the \"CODE\" and \"OUTPUT\" strings\n",
    "                clean_element = json.loads(element)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                # If it's not JSON, just treat it as a regular string\n",
    "                clean_element = str(element).strip('\"')\n",
    "            formatted_elements.append(clean_element)\n",
    "\n",
    "        # Join the cleaned elements with a colon\n",
    "        formatted_tuple = \": \".join(formatted_elements)\n",
    "        formatted_parts.append(formatted_tuple)\n",
    "\n",
    "    # Join all the formatted tuples with a newline\n",
    "    return \"\\n\".join(formatted_parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"supervisor_memory.db\"\n",
    "# if os.path.exists(db_path):\n",
    "#     os.remove(db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e7505ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t--- Starting Crew for RAG Agent ---\n",
      "\n",
      "🙎‍♂️: What was my previous question?\n",
      "\t I need to check with rag_task\n",
      "\t# --- Historical Context --- #\n",
      "\tsupervisor_agent: rag_task\n",
      "Agent: You should discuss your need for a flexible work arrangement, such as remote work or adjusted hours, with your supervisor or the HR department. They will review your request and determine if it aligns with company policies and can be accommodated based on the nature of your role and operational requirements.\n",
      "User: Can I request a flexible work arrangement?\n",
      "\t# -------------------------- #\n",
      "🤖: You asked about requesting a flexible work arrangement. According to HR policies, you should discuss your need for a flexible work arrangement with your supervisor or the HR department. They will review your request and determine if it aligns with company policies and can be accommodated based on the nature of your role and operational requirements.\n",
      "\tCheckpoint saved with ID: 12\n",
      "\n",
      "🙎‍♂️: exit\n",
      "Saving History ...\n"
     ]
    }
   ],
   "source": [
    "# Defining Control Flow.\n",
    "def main():\n",
    "    \"\"\"Main function to kickoff the Crew.\"\"\"\n",
    "    memory = SQLiteMemory(db_path=db_path)\n",
    "        \n",
    "    print(\"\\n\\t--- Starting Crew for RAG Agent ---\")\n",
    "\n",
    "    while True:\n",
    "        # Load from the previous checkpoint\n",
    "        history = memory.load_recent(3)\n",
    "        # Get the final formatted text\n",
    "        history = convert_tuple_list_to_text(history)\n",
    "        # print(\"Loaded history.\")\n",
    "\n",
    "        user_query = input(\"Enter your query (or type 'exit' to quit): \")\n",
    "        print(f\"\\n🙎‍♂️: {user_query}\")\n",
    "\n",
    "        # Breaking the loop if exit or quit was input\n",
    "        if user_query.lower() in ['exit', 'quit']:\n",
    "            print(\"Saving History ...\")\n",
    "            memory.close()\n",
    "            break\n",
    "\n",
    "        decision = supervisor_crew.kickoff(inputs={'query': user_query, 'context': history})\n",
    "        print(f\"\\t I need to check with {decision}\")\n",
    "\n",
    "        print(\"\\t# --- Historical Context --- #\")\n",
    "        print(f\"\\t{history}\")\n",
    "        print(\"\\t# -------------------------- #\")\n",
    "\n",
    "        if decision.raw == 'coding_task':\n",
    "            result = coding_crew.kickoff(inputs= {'query': user_query, 'context': history})\n",
    "            print(f\"🤖: {result}\")\n",
    "        elif decision.raw == 'rag_task':\n",
    "            result = rag_crew.kickoff(inputs= {'query': user_query, 'context': history})\n",
    "            print(f\"🤖: {result}\")\n",
    "        else:\n",
    "            print(f\"🤖: {decision}\")\n",
    "\n",
    "        # Saving History\n",
    "        memory.save(\"User\", user_query)\n",
    "        memory.save(\"Agent\", result.raw)\n",
    "\n",
    "        # Save a checkpoint after a key decision is made\n",
    "        checkpoint_id = memory.save_checkpoint(\"supervisor_agent\", decision.raw)\n",
    "        print(f\"\\tCheckpoint saved with ID: {checkpoint_id}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa298507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a python code to see if a user given integer is prime or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-ai-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
